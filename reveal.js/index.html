<!doctype html>
<html lang="en">
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<title>reveal.js</title>

		<link rel="stylesheet" href="dist/reset.css">
		<link rel="stylesheet" href="dist/reveal.css">
		<link rel="stylesheet" href="dist/theme/black.css">

		<!-- Theme used for syntax highlighted code -->
		<link rel="stylesheet" href="plugin/highlight/monokai.css">

		<style type="text/css">
			p { text-align: left; }

			.code-wrapper {
				width: max-content !important;
			}
			.reveal pre code {
				max-height: unset !important;
				overflow: visible;
			}
		</style>

	</head>
	<body>
		<div class="reveal">
			<div class="slides">
				<section data-markdown>
					<textarea data-template>
# Adventures in IR: Plundering Core.Compiler

Dr Frames White (she/her)

JuliaHub

---

## This conference is much easier to get to
<img src="assets/map.png" alt="map of flight Perth to Amsterdam stopping in Singapore." style="height:400px;">

Only 20 hours in transit, not 40 hours.  
Only 1/3rd the way round the would, not half.  
Much less remote than Boston.



---

## ðŸ’¬ What is this talk?

This is about writing custom optimization passes that work using the tools that are built into the compiler itself.

In contrast to say IRTools.jl which reimplements analysis and modification utilities itself

It one key part of DAECompiler.jl which is used in Cedar,
and behind Diffractor's demand driven forwards mode AD.
It's also used for Will Tebbut's Tapir.jl reverse mode AD.

---

## ðŸ’¡ Why would I want to do this?

- Run different optimization pipeline 
	- Disable inlining
	- Allow union splitting with more than 4 elements in the union
- Generate multiple functions from 1 definition
	- DAECompile generates about a dozen different functions like Jacobians and callbacks from a single function definition.
	- This kinda thing generally requires custom intrinsics.

---

## âš  A warning: this is unstable internals

This is so far away from a public API.
We are in the deep intercontinential ocean.
The light of god can not reach you here.


See Valentin Churavy's talk for some parts of stablizing some of this.
But it will likely remain not fully public.

Various bits of it change fairly often.
I suggest looking in Diffractor's source for the various version branches.
This talk is with reference to v1.12.0-DEV.469.

In particular, the trick of giving typed IR to an OpaqueCloure is likely to change.
It's not what they were really made for, it just happens to be convienent.

But the general content and conception of this talk should remain useful.

---

## A lot of the utilities are not in the Base namespace
When you do `for` that lowers to calls to `iterate` in the current namespace.
Similar for `getindex` and `setindex`, and indexing with `begin` and `end`.
But `Core` is a different namespace to `Base`.
So some things are broken if you are using from normal julia code which is in main with Base exporting them.
But you can do a manual method merge across the namespaces.
And some (like `getindex(::IRCode, ::SSAValue)` after Julia v1.11.0-DEV.258) are already defined.

For example:
```julia
const CC = Core.Compiler
Base.lastindex(x::CC.InstructionStream) = CC.length(x)
```

---

## ðŸª  The compiler pipeline
You are likely familiar with the compilation pipeline of:

1. Source code
2. Parsing -> AST
	- Macros run here
3. Lowering -> Untyped IR
	- Cassette, Zygote and JuliaInterpetter run here
4. Type Inference -> Typed IR 
	- loop here running julia optimization passes
	- This stage is what this talk is about
5. Code Generation -> LLVM IR
	- loop here running LLVM optimization passes
	- Enzyme, and GPU Compiler run here.
6. Assembling -> Machine Code

---

## Let's zoom-in on step 4: the Typed IR
If you have used `@code_typed` you get back typed IR, as a `CodeInfo` object.
It's not quiet SSA because it has slots (basically variables).

You want a `IRCode` object, which you can get from `Base.code_ircode`.
This is the representation that is used with in the optimizer.
it is a true SSA, and it is also enriched with the CFG.
For display purposes it can be converted back to a `CodeInfo` object.

This is what is actually created and manipulated during this step,
and what almost all Julia's own optimization passes are running on.

---

# Parts

---

## Instrucions
We can think of IR code as a list of instructions.

For the `ii`th instruction we have:

```julia
ir[SSAValue(ii)][:stmt]  # The expression
ir[SSAValue(ii)][:typ]   # the lattices (including type lattice)
ir[SSAValue(ii)][:flag] # flags
# + some other stuff
```

the `:stmt` can hold a `Expr`, a `SSAValue`, an `Argument` or a literal

---

## Expr
Broadly speaking inside SSA IR an Expr is not so different from in the AST.
But it is restricted.
Most significantly it can't be nested, as it is **Single Statement** Assigment.
It can only contain `SSAValue`s, `Argument`s and literals.


**No:**
```llvm
%1 = foo(2*2)
```
**Yes:**
```llvm
%1 = 2*2
%2 = foo(%1)
```
---

## SSAValues
An `SSAValue` is the value of a single statement..
Written `%1`, `%2` etc

```julia-repl
julia> foo() = 2 * (@noinline rand())
foo (generic function with 1 method)

julia> Base.code_ircode(foo, Tuple{})
1 1 â”€ %1 = invoke Main.rand()::Float64                â”‚ 
	â”‚   %2 = Base.mul_float(2.0, %1)::Float64           â”‚â•» *
	â””â”€â”€      return %2                                  â”‚ 
	=> Float64                                           
```

---

## Arguments
An `Argument`, written `_1`, `_2`,`_3` etc represent the arguments to the functions.
Functionally they are much like `SSAValue`s but without instructions assoicated with them
`_1` is the function object itself, so its first argument is `_2`


```julia-repl
julia> Base.code_ircode(+, (Int, Int),) |> only
87 1 â”€ %1 = Base.add_int(_2, _3)::Int64                  â”‚
	â””â”€â”€      return %1                                    â”‚
	=> Int64           
```

---

## Invokes and Calls

You are familar with `Expr(:call, f, args...)` from the AST.
But in the `IRCode` we also have `Expr(:invoke, method_instance, f, args...)`

- Call is used for dynamic dispatches
- Invoke is used for static dispatches

Running type inference will replace type-known calls with invokes.
So generally insert calls, and let type-inference work it out.

---

## Basic blocks
Lowering turns ASTs into flat structures.
It remove `if-else`, `for`, `while` replacing them with `goto`s and `goto if not`s.
However, structure still remains: you run a block of code before hiting a point that you can jump to.
These are basic blocks

```julia-repl
julia> function qux()
		x=0.0
		if (@noinline rand(Bool))
			x += 10(@noinline rand())
		end
		return x
		end;

julia> Base.code_ircode(qux) |> first
3 1 â”€ %1 = invoke Main.rand(Main.Bool::Type{Bool})::Bool            â”‚ 
	â””â”€â”€      goto #3 if not %1                                        â”‚ 
4 2 â”€ %3 = invoke Main.rand()::Float64                              â”‚ 
	â”‚   %4 = Base.mul_float(10.0, %3)::Float64                        â”‚â•» *
	â””â”€â”€ %5 = Base.add_float(0.0, %4)::Float64                         â”‚â•» +
6 3 â”„ %6 = Ï† (#2 => %5, #1 => 0.0)::Float64                         â”‚ 
	â””â”€â”€      return %6                                                â”‚ 
	=> Float64 
```

---

## Control Flow Graph (CFG)
We can extract the possible paths through the basic blocks as a graph.

<div>
<div style="display: inline-block; width: 50%;">

```julia-repl
julia> ir.cfg
CFG with 3 blocks:
	bb 1 (stmts 1:2) â†’ bb 3, 2
	bb 2 (stmts 3:5) â†’ bb 3
	bb 3 (stmts 6:7)

julia> ir.cfg.blocks[2].stmts
3-element Core.Compiler.StmtRange:
	3
	4
	5

julia> ir.cfg.blocks[2].preds
1-element Vector{Int64}:
	1

julia> ir.cfg.blocks[2].succs
1-element Vector{Int64}:
	3
```

</div>

<div style="display: inline-block; width: 49%">
	<img src="assets/CFG.png" alt="diagram of the cfg">
</div>
</div>

---

## Phi nodes
Phi nodes are kinda like `ifelse` statements, but they know which basic block was just left.

For example
```julia
%33 = Ï† (#2 => %8, #4 => %17, #6 => %26, #8 => %31)::Union{Float32, Int32}
```

says to set `%33` to:
	- `%8` if we came from `#2`
	- `%17` if we came from `#4`
	- `%26` if we came from `#6`
	- `%31` if we came from `#8`

They are weird little time-reversed friends.
Almost opposite of a `goto` -- `if_came_from`.

---

## Pi nodes
These are like type-assertions.
They are facts that are certain to be true, so the compiler can use them.
They are often inserted by type assertions or banching on types, etc.
For example they are inserted during union-splitting

```julia=-repl
julia> int32_or_float32() = rand((rand() > 0.5 ? Int32 : Float32));

julia> function bar()
		a = @noinline int32_or_float32()
		return a + a
		end;

julia> Base.code_ircode(bar) |> only
2 1 â”€ %1  = invoke Main.int32_or_float32()::Union{Float32, Int32}
3 â”‚   %2  = (isa)(%1, Float32)::Bool                     â”‚     
	â”‚   %3  = (isa)(%1, Float32)::Bool                     â”‚     
	â”‚   %4  = (Core.Intrinsics.and_int)(%2, %3)::Bool      â”‚     
	â””â”€â”€       goto #3 if not %4                            â”‚     
	2 â”€ %6  = Ï€ (%1, Float32)                              â”‚     
	â”‚   %7  = Ï€ (%1, Float32)                              â”‚     
	â”‚   %8  = Base.add_float(%6, %7)::Float32              â”‚â•»     +
	â””â”€â”€       goto #9                                      â”‚     
	3 â”€ ...     
	8 â”€ %29 = Ï€ (%1, Int32)                                â”‚     
	â”‚   %30 = Ï€ (%1, Int32)                                â”‚     
	â”‚   %31 = Base.add_int(%29, %30)::Int32                â”‚â•»     +
	â””â”€â”€       goto #9                                      â”‚     
	9 â”„ %33 = Ï† (#2 => %8, #4 => %17, #6 => %26, #8 => %31)::Union{Filoat32, Int32}
	â””â”€â”€       return %33                                   â”‚     
	=> Union{Float32, Int32}                                    
```

---

# How Tos

---

## How to replace an instruction

```julia
inst = ir[SSAValue(1)]
inst[:stmt] = ...  # new statement here
ir[idx][:info] = CC.NoCallInfo()
inst[:typ] =  # if the know type put it here. OR: put `Any` and:
inst[:flag] |= Core.Compiler.IR_FLAG_REFINED  # mark for type inference
```
Then make sure to (re-)run type inference after, if you didn't put in a type.
(Or it will work but be really slow)

---

## How do I delete an instruction?
Functionally there is no reason to actually delete instructions -- that would require renumbering the SSAValues, which is expensive and if you are doing it best done in batch (more on that later).

Instead set it to `nothing` which will be trivially optimized out as an unusued literal

```julia
inst = ir[SSAValue(ii)]
inst[:stmt] = nothing
inst[:typ] = Nothing
```


---

## How do I insert an instruction

```julia
insert_node!(
	ir::Core.Compiler.IRCode,
	pos::Core.SSAValue,
	newinst::Core.Compiler.NewInstruction,
	attach_after::Bool)

NewInstruction(
	stmt, type,
	info::Core.Compiler.CallInfo == NoCallInfo()
	line=nothing  # copy line above
	flag=nothing  # automatically determined from context
)
```

Often if it is nontrivial to express as a single statement,
you can instead define a little local function in your transform code then insert reference to that function (as a literal)

---



## How do I run the full compiler pipeline manually?

---

## How do I run inference?

```julia
"run type inference and constant propagation on the ir"
function infer_ir!(
	ir::CC.IRCode,
	interp::CC.AbstractInterpreter, 
	mi::CC.MethodInstance
)
    
	method_info = CC.MethodInfo(#=propagate_inbounds=#true, nothing)
    min_world = world = CC.get_world_counter(interp)
    max_world = Base.get_world_counter()
    spec_types = ir.argtypes
    irsv = CC.IRInterpretationState(
		interp, method_info, ir, mi, spec_types,
		world, min_world, max_world
	)
    rt = CC._ir_abstract_constant_propagation(interp, irsv)
    return ir
end
```
---
## How do i get an interpreter?
If doing custom abstract interpretation (see Keno's talk) you already have one.
If not:
```julia
CC.NativeInterpreter(;
	inf_params::InferenceParameters, opt_params::OptimizationParameters
)
```

<div class="r-stack">
<div class="fragment current-visible">

`InferenceParameters(; kwargs...)` 
- `max_methods = 3`
- `max_union_splitting = 4`
- `max_apply_union_enum = 8`
- `max_tuple_splat = 32`
- `tuple_complexity_limit_depth = 3`

</div>

<div class="fragment">

`OptimizationParameters(; kwargs...)`
- `inlining::Bool = inlining_enabled()`
- `inline_cost_threshold = 100`
- `max_tuple_splat = 32`
- `compilesig_invokes = true`
- `assume_fatal_throw = false`

</div>
</div>

notes:
both OptimizationParameters and InferenceParameters have really good docstrings.
Unlike most things.

---

## How do I get a fresh method instance for inference?

```julia
function get_toplevel_mi_from_ir(ir::CC.IRCode, _module::Module)
    mi = ccall(:jl_new_method_instance_uninit,Ref{CC.MethodInstance},())
    mi.specTypes = Tuple{map(CC.widenconst, ir.argtypes)...}
    mi.def = _module
    return mi
end 
```

notes:
explain `CC.widenconst` drops extra lattices.
As name suggest the most common extra lattice is the constant lattice.
Which will show up in IR.argtypes for the function object.

---

## What is a custom intrinsic?
For our purpose a custom intrinsic is something that
1. has special handling by our custom pass
2. doesn't end up in the final code after our passes are done

Keno and Shuhei's talk should cover this in more detail.
Since a major use of custom intrinsics is to push things into a custom latice during abstract interpretation.

---

## How do I define a custom intrinsic?
We can simply use a function that does nothing.
We just need to ensure that no earlier optimize pass removes it,
e.g. via inlining and seeing it is effect free.

**TODO** copy example from DAECompiler

					</textarea>
				</section>
			</div>
		</div>

		<script src="dist/reveal.js"></script>
		<script src="plugin/notes/notes.js"></script>
		<script src="plugin/markdown/markdown.js"></script>
		<script src="plugin/highlight/highlight.js"></script>
		<script>
			// More info about initialization & config:
			// - https://revealjs.com/initialization/
			// - https://revealjs.com/config/
			Reveal.initialize({
				hash: true,
				margin: 0.1,
//				width: '90%',
//				height: '50%',

				// Learn about plugins: https://revealjs.com/plugins/
				plugins: [ RevealMarkdown, RevealHighlight, RevealNotes ]
			});
		</script>
	</body>
</html>
